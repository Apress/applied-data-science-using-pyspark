{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hypothesis Testing - ChiSquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sparksession\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"HypothesisTesting\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pValues: [0.6872892787909721,0.6822703303362126]\n",
      "degreesOfFreedom: [2, 3]\n",
      "statistics: [0.75,1.5]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "data = [(0.0, Vectors.dense(0.5, 10.0)),\n",
    "        (0.0, Vectors.dense(1.5, 20.0)),\n",
    "        (1.0, Vectors.dense(1.5, 30.0)),\n",
    "        (0.0, Vectors.dense(3.5, 30.0)),\n",
    "        (0.0, Vectors.dense(3.5, 40.0)),\n",
    "        (1.0, Vectors.dense(3.5, 40.0))]\n",
    "df = spark.createDataFrame(data, [\"label\", \"features\"])\n",
    "\n",
    "r = ChiSquareTest.test(df, \"features\", \"label\").head()\n",
    "print(\"pValues: \" + str(r.pValues))\n",
    "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hypothesis Testing -  Kolmogorov-Smirnov test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov test summary:\n",
      "degrees of freedom = 0 \n",
      "statistic = 0.539827837277029 \n",
      "pValue = 0.06821463111921133 \n",
      "Low presumption against null hypothesis: Sample follows theoretical distribution.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "parallelData = spark.sparkContext.parallelize([0.1, 0.15, 0.2, 0.3, 0.25])\n",
    "\n",
    "# run a KS test for the sample versus a standard normal distribution\n",
    "testResult = Statistics.kolmogorovSmirnovTest(parallelData, \"norm\", 0, 1)\n",
    "# summary of the test including the p-value, test statistic, and null hypothesis\n",
    "# if our p-value indicates significance, we can reject the null hypothesis\n",
    "# Note that the Scala functionality of calling Statistics.kolmogorovSmirnovTest with\n",
    "# a lambda to calculate the CDF is not made available in the Python API\n",
    "print(testResult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.random import RandomRDDs\n",
    "# Generate a random double RDD that contains 1 million i.i.d. values drawn from the\n",
    "# standard normal distribution `N(0, 1)`, evenly distributed in 10 partitions.\n",
    "u = RandomRDDs.normalRDD(spark.sparkContext, 1000000, 10)\n",
    "# Apply a transform to get a random double RDD following `N(1, 4)`.\n",
    "v = u.map(lambda x: 1.0 + 2.0 * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+---+------+------+------+\n",
      "|Geography|NumOfProducts|Age|Gender|Tenure|Exited|\n",
      "+---------+-------------+---+------+------+------+\n",
      "|France   |3            |42 |Female|8     |1     |\n",
      "|France   |2            |39 |Female|1     |0     |\n",
      "|France   |2            |50 |Male  |7     |0     |\n",
      "|France   |1            |27 |Male  |2     |0     |\n",
      "|France   |2            |31 |Male  |6     |0     |\n",
      "|Germany  |2            |45 |Male  |3     |0     |\n",
      "|Germany  |1            |58 |Male  |1     |1     |\n",
      "|France   |2            |41 |Male  |8     |0     |\n",
      "|Spain    |2            |32 |Female|8     |0     |\n",
      "|Spain    |1            |38 |Female|4     |1     |\n",
      "+---------+-------------+---+------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "file_location = \"churn_modelling.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "df = spark.read.format(file_type)\\\n",
    ".option(\"inferSchema\", infer_schema)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(file_location)\n",
    "\n",
    "# Simple Random Sampling without replacement\n",
    "df=df.select('Geography','NumOfProducts','Age','Gender','Tenure','Exited')\n",
    "df_srs_without_rep = df.sample(False, 0.5, 23)\n",
    "df_srs_without_rep.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+---+------+------+------+\n",
      "|Geography|NumOfProducts|Age|Gender|Tenure|Exited|\n",
      "+---------+-------------+---+------+------+------+\n",
      "|Spain    |1            |41 |Female|1     |0     |\n",
      "|France   |2            |39 |Female|1     |0     |\n",
      "|Spain    |1            |43 |Female|2     |0     |\n",
      "|Germany  |4            |29 |Female|4     |1     |\n",
      "|France   |2            |31 |Male  |6     |0     |\n",
      "|France   |2            |31 |Male  |6     |0     |\n",
      "|France   |2            |25 |Female|5     |0     |\n",
      "|Spain    |2            |32 |Female|8     |0     |\n",
      "|Spain    |1            |38 |Female|4     |1     |\n",
      "|France   |2            |46 |Male  |3     |0     |\n",
      "+---------+-------------+---+------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple Random Sampling with replacement\n",
    "df_srs_without_rep = df.sample(True, 0.5, 23)\n",
    "df_srs_without_rep.show(10,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df = df.withColumn(\"Exited\", df[\"Exited\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|             Exited|\n",
      "+-------+-------------------+\n",
      "|  count|              10000|\n",
      "|   mean|             0.2037|\n",
      "| stddev|0.40276858399486065|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Exited').describe().show()\n",
    "stratified_sampled = df.sampleBy(\"Exited\", fractions={0: 0.5, 1: 0.5}, seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|             Exited|\n",
      "+-------+-------------------+\n",
      "|  count|               5022|\n",
      "|   mean| 0.2078853046594982|\n",
      "| stddev|0.40583469642655867|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stratified_sampled.select('Exited').describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
