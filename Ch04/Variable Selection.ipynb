{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"bank-full.csv\"\n",
    "target_variable_name = \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
      "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
      "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
      "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
      "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
      "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|\n",
      "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|\n",
      "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|\n",
      "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|\n",
      "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|\n",
      "| 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|\n",
      "| 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|\n",
      "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|\n",
      "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|\n",
      "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|\n",
      "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|\n",
      "| 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|\n",
      "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|\n",
      "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|\n",
      "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|\n",
      "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.csv(filename, header=True, inferSchema=True, sep=';')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45211"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>40.93621021432837</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1362.2720576850766</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>15.80641879188693</td>\n",
       "      <td>None</td>\n",
       "      <td>258.1630797814691</td>\n",
       "      <td>2.763840658246887</td>\n",
       "      <td>40.19782796222158</td>\n",
       "      <td>0.5803233726305546</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.618762040975401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3044.7658291685243</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.322476153044589</td>\n",
       "      <td>None</td>\n",
       "      <td>257.5278122651712</td>\n",
       "      <td>3.0980208832791813</td>\n",
       "      <td>100.12874599059818</td>\n",
       "      <td>2.3034410449312164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>18</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>-8019</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>1</td>\n",
       "      <td>apr</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>95</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>102127</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>31</td>\n",
       "      <td>sep</td>\n",
       "      <td>4918</td>\n",
       "      <td>63</td>\n",
       "      <td>871</td>\n",
       "      <td>275</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 age      job   marital education default  \\\n",
       "0   count               45211    45211     45211     45211   45211   \n",
       "1    mean   40.93621021432837     None      None      None    None   \n",
       "2  stddev  10.618762040975401     None      None      None    None   \n",
       "3     min                  18   admin.  divorced   primary      no   \n",
       "4     max                  95  unknown    single   unknown     yes   \n",
       "\n",
       "              balance housing   loan   contact                day  month  \\\n",
       "0               45211   45211  45211     45211              45211  45211   \n",
       "1  1362.2720576850766    None   None      None  15.80641879188693   None   \n",
       "2  3044.7658291685243    None   None      None  8.322476153044589   None   \n",
       "3               -8019      no     no  cellular                  1    apr   \n",
       "4              102127     yes    yes   unknown                 31    sep   \n",
       "\n",
       "            duration            campaign               pdays  \\\n",
       "0              45211               45211               45211   \n",
       "1  258.1630797814691   2.763840658246887   40.19782796222158   \n",
       "2  257.5278122651712  3.0980208832791813  100.12874599059818   \n",
       "3                  0                   1                  -1   \n",
       "4               4918                  63                 871   \n",
       "\n",
       "             previous poutcome      y  \n",
       "0               45211    45211  45211  \n",
       "1  0.5803233726305546     None   None  \n",
       "2  2.3034410449312164     None   None  \n",
       "3                   0  failure     no  \n",
       "4                 275  unknown    yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('y', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the records by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|education|count|\n",
      "+---------+-----+\n",
      "|  unknown| 1857|\n",
      "| tertiary|13301|\n",
      "|secondary|23202|\n",
      "|  primary| 6851|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('education').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the records by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "| no|39922|\n",
      "|yes| 5289|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(target_variable_name).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by Multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-----+\n",
      "|education|  y|count|\n",
      "+---------+---+-----+\n",
      "|  unknown| no| 1605|\n",
      "| tertiary| no|11305|\n",
      "|secondary| no|20752|\n",
      "|  unknown|yes|  252|\n",
      "|  primary| no| 6260|\n",
      "|  primary|yes|  591|\n",
      "|secondary|yes| 2450|\n",
      "| tertiary|yes| 1996|\n",
      "+---------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(['education',target_variable_name]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------------------+\n",
      "|  y|      avg(balance)|          avg(age)|\n",
      "+---+------------------+------------------+\n",
      "| no|1303.7149691899203| 40.83898602274435|\n",
      "|yes|1804.2679145396105|41.670069956513515|\n",
      "+---+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import * \n",
    "df.groupBy(target_variable_name).agg({'balance':'avg', 'age': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import approxCountDistinct, countDistinct\n",
    "\n",
    "\"\"\"\n",
    "Note: approxCountDistinct and countDistinct can be used interchangeably. Only difference is the computation time. \n",
    "\n",
    "\"approxCountDistinct\" is useful for large datasets \n",
    "\"countDistinct\" for small and medium datasets.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cardinality_calculation(df, cut_off=1):\n",
    "    cardinality = df.select(*[approxCountDistinct(c).alias(c) for c in df.columns])\n",
    "    \n",
    "    ## convert to pandas for efficient calculations\n",
    "    final_cardinality_df = cardinality.toPandas().transpose()\n",
    "    final_cardinality_df.reset_index(inplace=True) \n",
    "    final_cardinality_df.rename(columns={0:'Cardinality'}, inplace=True) \n",
    "    \n",
    "    #select variables with cardinality of 1\n",
    "    vars_selected = final_cardinality_df['index'][final_cardinality_df['Cardinality'] <= cut_off] \n",
    "    \n",
    "    return final_cardinality_df, vars_selected\n",
    "\n",
    "cardinality_df, cardinality_vars_selected = cardinality_calculation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>7375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contact</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>duration</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  Cardinality\n",
       "0         age           76\n",
       "1         job           11\n",
       "2     marital            3\n",
       "3   education            4\n",
       "4     default            2\n",
       "5     balance         7375\n",
       "6     housing            2\n",
       "7        loan            2\n",
       "8     contact            3\n",
       "9         day           32\n",
       "10      month           12\n",
       "11   duration         1605\n",
       "12   campaign           47\n",
       "13      pdays          547\n",
       "14   previous           42\n",
       "15   poutcome            4\n",
       "16          y            2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: index, dtype: object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_vars_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values check\n",
    "from pyspark.sql.functions import count, when, isnan, col\n",
    "\n",
    "# miss_percentage is set to 80% as discussed in the book\n",
    "def missing_calculation(df, miss_percentage=0.80):\n",
    "    \n",
    "    #checks for both NaN and null values\n",
    "    missing = df.select(*[count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    length_df = df.count()\n",
    "    ## convert to pandas for efficient calculations\n",
    "    final_missing_df = missing.toPandas().transpose()\n",
    "    final_missing_df.reset_index(inplace=True) \n",
    "    final_missing_df.rename(columns={0:'missing_count'}, inplace=True) \n",
    "    final_missing_df['missing_percentage'] = final_missing_df['missing_count']/length_df\n",
    "    \n",
    "    #select variables with cardinality of 1\n",
    "    vars_selected = final_missing_df['index'][final_missing_df['missing_percentage'] >= miss_percentage] \n",
    "    \n",
    "    return final_missing_df, vars_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df, missing_vars_selected = missing_calculation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contact</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>duration</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  missing_count  missing_percentage\n",
       "0         age              0                 0.0\n",
       "1         job              0                 0.0\n",
       "2     marital              0                 0.0\n",
       "3   education              0                 0.0\n",
       "4     default              0                 0.0\n",
       "5     balance              0                 0.0\n",
       "6     housing              0                 0.0\n",
       "7        loan              0                 0.0\n",
       "8     contact              0                 0.0\n",
       "9         day              0                 0.0\n",
       "10      month              0                 0.0\n",
       "11   duration              0                 0.0\n",
       "12   campaign              0                 0.0\n",
       "13      pdays              0                 0.0\n",
       "14   previous              0                 0.0\n",
       "15   poutcome              0                 0.0\n",
       "16          y              0                 0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: index, dtype: object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vars_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_type(df):\n",
    "    \n",
    "    vars_list = df.dtypes\n",
    "    char_vars = []\n",
    "    num_vars = []\n",
    "    for i in vars_list:\n",
    "        if i[1] in ('string'):\n",
    "            char_vars.append(i[0])\n",
    "        else:\n",
    "            num_vars.append(i[0])\n",
    "    \n",
    "    return char_vars, num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vars, num_vars = variable_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome',\n",
       " 'y']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def category_to_index(df, char_vars):\n",
    "    \n",
    "    char_df = df.select(char_vars)\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=c+\"_index\", handleInvalid=\"keep\") for c in char_df.columns]\n",
    "    pipeline = Pipeline(stages=indexers)\n",
    "    char_labels = pipeline.fit(char_df)\n",
    "    df = char_labels.transform(df)\n",
    "    return df, char_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, char_labels = category_to_index(df, char_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'int'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('poutcome', 'string'),\n",
       " ('y', 'string'),\n",
       " ('job_index', 'double'),\n",
       " ('marital_index', 'double'),\n",
       " ('education_index', 'double'),\n",
       " ('default_index', 'double'),\n",
       " ('housing_index', 'double'),\n",
       " ('loan_index', 'double'),\n",
       " ('contact_index', 'double'),\n",
       " ('month_index', 'double'),\n",
       " ('poutcome_index', 'double'),\n",
       " ('y_index', 'double')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([c for c in df.columns if c not in char_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, char_vars):\n",
    "    mapping = dict(zip([i + '_index' for i in char_vars], char_vars))\n",
    "    df = df.select([col(c).alias(mapping.get(c, c)) for c in df.columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rename_columns(df, char_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('balance', 'int'),\n",
       " ('day', 'int'),\n",
       " ('duration', 'int'),\n",
       " ('campaign', 'int'),\n",
       " ('pdays', 'int'),\n",
       " ('previous', 'int'),\n",
       " ('job', 'double'),\n",
       " ('marital', 'double'),\n",
       " ('education', 'double'),\n",
       " ('default', 'double'),\n",
       " ('housing', 'double'),\n",
       " ('loan', 'double'),\n",
       " ('contact', 'double'),\n",
       " ('month', 'double'),\n",
       " ('poutcome', 'double'),\n",
       " ('y', 'double')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  y|count|\n",
      "+---+-----+\n",
      "|0.0|39922|\n",
      "|1.0| 5289|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('y').count().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#assemble individual columns to one column - 'features'\n",
    "def assemble_vectors(df, features_list, target_variable_name):\n",
    "    stages = []\n",
    "    #assemble vectors\n",
    "    assembler = VectorAssembler(inputCols=features_list, outputCol='features')\n",
    "    stages = [assembler]\n",
    "    #select all the columns + target + newly created 'features' column\n",
    "    selectedCols = [target_variable_name, 'features'] + features_list\n",
    "    #use pipeline to process sequentially\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    #assembler model\n",
    "    assembleModel = pipeline.fit(df)\n",
    "    #apply assembler model on data\n",
    "    df = assembleModel.transform(df).select(selectedCols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude target variable and select all other feature vectors\n",
    "features_list = df.columns\n",
    "#features_list = char_vars #this option is used only for ChiSqselector\n",
    "features_list.remove(target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'balance',\n",
       " 'day',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function on our dataframe\n",
    "df = assemble_vectors(df, features_list, target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+\n",
      "|  y|            features|age|balance|day|duration|campaign|pdays|previous| job|marital|education|default|housing|loan|contact|month|poutcome|\n",
      "+---+--------------------+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 58|   2143|  5|     261|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 44|     29|  5|     151|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 33|      2|  5|      76|       1|   -1|       0| 7.0|    0.0|      0.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 47|   1506|  5|      92|       1|   -1|       0| 0.0|    0.0|      3.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|[33.0,1.0,5.0,198...| 33|      1|  5|     198|       1|   -1|       0|11.0|    1.0|      3.0|    0.0|    1.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 35|    231|  5|     139|       1|   -1|       0| 1.0|    0.0|      1.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|[28.0,447.0,5.0,2...| 28|    447|  5|     217|       1|   -1|       0| 1.0|    1.0|      1.0|    0.0|    0.0| 1.0|    1.0|  0.0|     0.0|\n",
      "|0.0|[42.0,2.0,5.0,380...| 42|      2|  5|     380|       1|   -1|       0| 7.0|    2.0|      1.0|    1.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 58|    121|  5|      50|       1|   -1|       0| 5.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 43|    593|  5|      55|       1|   -1|       0| 2.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 41|    270|  5|     222|       1|   -1|       0| 3.0|    2.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 29|    390|  5|     137|       1|   -1|       0| 3.0|    1.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 53|      6|  5|     517|       1|   -1|       0| 2.0|    0.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 58|     71|  5|      71|       1|   -1|       0| 2.0|    0.0|      3.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 57|    162|  5|     174|       1|   -1|       0| 4.0|    0.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 51|    229|  5|     353|       1|   -1|       0| 5.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|[45.0,13.0,5.0,98...| 45|     13|  5|      98|       1|   -1|       0| 3.0|    1.0|      3.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 57|     52|  5|      38|       1|   -1|       0| 0.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,1,2,3,4,5,...| 60|     60|  5|     219|       1|   -1|       0| 5.0|    0.0|      2.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "|0.0|(16,[0,2,3,4,5,7,...| 33|      0|  5|      54|       1|   -1|       0| 4.0|    0.0|      0.0|    0.0|    0.0| 0.0|    1.0|  0.0|     0.0|\n",
      "+---+--------------------+---+-------+---+--------+--------+-----+--------+----+-------+---------+-------+-------+----+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeric': [{'idx': 0, 'name': 'age'},\n",
       "  {'idx': 1, 'name': 'balance'},\n",
       "  {'idx': 2, 'name': 'day'},\n",
       "  {'idx': 3, 'name': 'duration'},\n",
       "  {'idx': 4, 'name': 'campaign'},\n",
       "  {'idx': 5, 'name': 'pdays'},\n",
       "  {'idx': 6, 'name': 'previous'},\n",
       "  {'idx': 7, 'name': 'job'},\n",
       "  {'idx': 8, 'name': 'marital'},\n",
       "  {'idx': 9, 'name': 'education'},\n",
       "  {'idx': 10, 'name': 'default'},\n",
       "  {'idx': 11, 'name': 'housing'},\n",
       "  {'idx': 12, 'name': 'loan'},\n",
       "  {'idx': 13, 'name': 'contact'},\n",
       "  {'idx': 14, 'name': 'month'},\n",
       "  {'idx': 15, 'name': 'poutcome'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for k, v in df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"].items():\n",
    "    features_df = pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>pdays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>marital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>poutcome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx       name\n",
       "0     0        age\n",
       "1     1    balance\n",
       "2     2        day\n",
       "3     3   duration\n",
       "4     4   campaign\n",
       "5     5      pdays\n",
       "6     6   previous\n",
       "7     7        job\n",
       "8     8    marital\n",
       "9     9  education\n",
       "10   10    default\n",
       "11   11    housing\n",
       "12   12       loan\n",
       "13   13    contact\n",
       "14   14      month\n",
       "15   15   poutcome"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled input vectors assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "#assemble and scale individual columns to one column - 'features2'\n",
    "def scaled_assemble_vectors(df, features_list, target_variable_name):\n",
    "    stages = []\n",
    "    #assemble vectors\n",
    "    assembler = VectorAssembler(inputCols=features_list, outputCol='assembled_features')\n",
    "    scaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol='features2')\n",
    "    stages = [assembler, scaler]\n",
    "    #select all the columns + target + newly created 'features' column\n",
    "    selectedCols = [target_variable_name, 'features2'] + features_list\n",
    "    #use pipeline to process sequentially\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    #assembler model\n",
    "    scaleAssembleModel = pipeline.fit(df)\n",
    "    #apply assembler model on data\n",
    "    df = scaleAssembleModel.transform(df).select(selectedCols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df.columns\n",
    "features_list.remove(target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaled_assemble_vectors(df, features_list, target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbuilt variable selection process – Without Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|pcaFeatures                                                 |\n",
      "+------------------------------------------------------------+\n",
      "|[-2143.4953647735806,-257.0420740676509,1.2449712753045807] |\n",
      "|[-29.29226175164622,-150.92888640669173,1.0493026899277984] |\n",
      "|[-2.150889773941845,-75.98191250436618,1.076065195538016]   |\n",
      "|[-1506.1823305908113,-89.21547154672724,1.2683999536975388] |\n",
      "|[-1.3750908349447704,-197.98356175494834,0.9892427009814176]|\n",
      "|[-231.26679712386607,-138.56034919503722,1.0576960891394662]|\n",
      "|[-447.4072782675638,-216.16541383839757,1.0066666548029033] |\n",
      "|[-2.7123264447441384,-379.9785828164356,0.875150469836411]  |\n",
      "|[-121.11144848214039,-49.756360259707854,1.1725853591922941]|\n",
      "|[-593.1146061641073,-53.89364261832045,1.1817022732261329]  |\n",
      "|[-270.4212341323415,-221.4869966182793,1.0170824073203284]  |\n",
      "|[-390.2608167665407,-136.27016909339142,1.0625336862698371] |\n",
      "|[-6.967616100129074,-516.9674558248698,0.800354576806597]   |\n",
      "|[-71.15006476185224,-70.84798774752204,1.1499619332807443]  |\n",
      "|[-162.33874829001962,-173.68095250690803,1.082334518324592] |\n",
      "|[-229.66539702564614,-352.5590565974903,0.9435034899629685] |\n",
      "|[-13.19533609012041,-97.95815345000725,1.0902785009000497]  |\n",
      "|[-52.08909854893974,-37.88319180402843,1.168229651755821]   |\n",
      "|[-60.42264272680139,-218.86732123338805,1.0462594933055773] |\n",
      "|[-0.11044203745870551,-53.98554342962402,1.0903138050957364]|\n",
      "+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "pca = PCA(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(df)\n",
    "\n",
    "result = model.transform(df).select(\"pcaFeatures\")\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.41021399e-04,  2.79524640e-04,  2.58353293e-03],\n",
       "       [-9.99998245e-01,  1.83654726e-03,  1.13892524e-04],\n",
       "       [-1.22934480e-05,  9.79995613e-04,  7.79347982e-03],\n",
       "       [-1.83671689e-03, -9.99996986e-01, -7.36955549e-04],\n",
       "       [ 1.48468991e-05,  1.01391994e-03,  2.75121381e-03],\n",
       "       [-1.13085547e-04,  7.49207153e-04, -9.99889046e-01],\n",
       "       [-1.26153895e-05, -6.36100089e-06, -1.04654388e-02],\n",
       "       [-1.78789640e-05, -4.11817349e-05,  5.51411389e-04],\n",
       "       [ 6.41085932e-06, -5.23364803e-05, -1.45349520e-04],\n",
       "       [-1.11185424e-05,  1.30366514e-05,  2.01500982e-04],\n",
       "       [ 2.91665702e-06,  4.42643869e-06,  3.95562163e-05],\n",
       "       [-1.12221341e-05,  1.26153926e-05,  6.17569266e-04],\n",
       "       [ 1.01623400e-05,  1.50687571e-05,  8.23933054e-05],\n",
       "       [-5.68377754e-07,  6.95393403e-05,  1.03951369e-03],\n",
       "       [-7.60886236e-05, -1.16754927e-04, -3.24662847e-03],\n",
       "       [-8.55162111e-06, -6.01853226e-05, -4.94522998e-03]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pc.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.9918, 0.0071, 0.0011])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.explainedVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = []\n",
    "for i in range(0, len(model.explainedVariance)):\n",
    "    x.append('PC' + str(i + 1))\n",
    "y = np.array(model.explainedVariance)\n",
    "z = np.cumsum(model.explainedVariance)\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.bar(x, y)\n",
    "plt.plot(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_svd_vector = df.rdd.map(lambda x: x['features'].toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[195] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svd_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "mat = RowMatrix(df_svd_vector)\n",
    "\n",
    "# Compute the top 5 singular values and corresponding singular vectors.\n",
    "svd = mat.computeSVD(5, computeU=True)\n",
    "U = svd.U       # The U factor is a RowMatrix.\n",
    "s = svd.s       # The singular values are stored in a local dense vector.\n",
    "V = svd.V       # The V factor is a local dense matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbuilt variable selection process – With Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChiSq selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "selector = ChiSqSelector(numTopFeatures=6, featuresCol=\"features\",\n",
    "                         outputCol=\"selectedFeatures\", labelCol=\"y\")\n",
    "\n",
    "chi_selector = selector.fit(df)\n",
    "    \n",
    "result = chi_selector.transform(df)\n",
    "\n",
    "print(\"ChiSqSelector output with top %d features selected\" % selector.getNumTopFeatures())\n",
    "print(\"Selected Indices: \", chi_selector.selectedFeatures)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_selector.selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['chisq_importance'] = features_df['idx'].apply(lambda x: 1 if x in chi_selector.selectedFeatures else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol=target_variable_name)\n",
    "rf_model = rf.fit(df)\n",
    "rf_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary output rf_output\n",
    "rf_output = rf_model.featureImportances\n",
    "features_df['Importance'] = features_df['idx'].apply(lambda x: rf_output[x] if x in rf_output.indices else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort values based on descending importance feature\n",
    "features_df.sort_values(\"Importance\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features_df.sort_values(\"Importance\", ascending=True, inplace=True)\n",
    "plt.barh(features_df['name'], features_df['Importance'])\n",
    "plt.title(\"Feature Importane Plot\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Variable Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "correlation_type = 'pearson' # 'pearson', 'spearman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in df.schema[\"features\"].metadata[\"ml_attr\"][\"attrs\"].items():\n",
    "    features_df = pd.DataFrame(v)\n",
    "column_names = list(features_df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector = df.rdd.map(lambda x: x['features'].toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = Statistics.corr(df_vector, method=correlation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corr_df = pd.DataFrame(matrix, columns=column_names, index=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_corr_df = pd.DataFrame(corr_df.abs().unstack().sort_values(kind='quicksort')).reset_index()\n",
    "final_corr_df.rename({'level_0': 'col1', 'level_1': 'col2', 0: 'correlation_value'}, axis=1, inplace=True)\n",
    "final_corr_df = final_corr_df[final_corr_df['col1'] != final_corr_df['col2']]\n",
    "final_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_cutoff = 0.65 #custom parameter\n",
    "final_corr_df[final_corr_df['correlation_value'] > correlation_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the estimator and transformer class\n",
    "from pyspark.ml import Estimator, Transformer\n",
    "\n",
    "# Parameter sharing class. We will use this for input column\n",
    "from pyspark.ml.param.shared import HasInputCol\n",
    "\n",
    "# Statistics class to calculate correlation\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import pandas as pd\n",
    "\n",
    "# custom class definition\n",
    "class CustomCorrelation(Estimator, Transformer, HasInputCol):\n",
    "    \"\"\"\n",
    "    A custom function to calculate the correlation between two variables.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    inputCol: default value (None)\n",
    "        Feature column name to be used for the correlation purpose. The input column should be assembled vector.\n",
    "        \n",
    "    correlation_type: 'pearson' or 'spearman'\n",
    "    \n",
    "    correlation_cutoff: float, default value (0.7), accepted values 0 to 1\n",
    "        Columns more than the specified cutoff will be displayed in the output dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize parameters for the function\n",
    "    def __init__(self, inputCol=None, correlation_type='pearson', correlation_cutoff=0.7):\n",
    "        \n",
    "        super(CustomCorrelation, self).__init__()\n",
    "        \n",
    "        assert inputCol, \"Please provide a assembled feature column name\"\n",
    "        \n",
    "        #self.inputCol is class parameter\n",
    "        self.inputCol = inputCol \n",
    "        \n",
    "        assert correlation_type == 'pearson' or correlation_type == 'spearman', \"Please provide \\\n",
    "                                a valid option for correlation type. 'pearson' or 'spearman'. \"\n",
    "        \n",
    "        #self.correlation_type is class parameter\n",
    "        self.correlation_type = correlation_type\n",
    "        \n",
    "        assert 0.0 <= correlation_cutoff <= 1.0, \"Provide a valid value for cutoff. Accepted range is 0 to 1\" \n",
    "        \n",
    "        #self.correlation_cutoff is class parameter\n",
    "        self.correlation_cutoff = correlation_cutoff\n",
    "        \n",
    "    # Estimator function, method inside a class, '_fit' - protected parameter\n",
    "    def _fit(self, df):\n",
    "        \n",
    "        for k, v in df.schema[self.inputCol].metadata[\"ml_attr\"][\"attrs\"].items():\n",
    "            features_df = pd.DataFrame(v)\n",
    "            \n",
    "        #self.column_names is class parameter, created for future use\n",
    "        self.column_names = list(features_df['name'])\n",
    "        \n",
    "        df_vector = df.rdd.map(lambda x: x[self.inputCol].toArray())\n",
    "        \n",
    "        #self.matrix is class parameter, created for future use\n",
    "        self.matrix = Statistics.corr(df_vector, method=correlation_type)\n",
    "        return self\n",
    "    \n",
    "    # Transformer function, method inside a class, '_transform' - protected parameter\n",
    "    def _transform(self, df):\n",
    "        \n",
    "        # making sure the estimator is called before transform\n",
    "        try:\n",
    "            if self.matrix:\n",
    "                pass\n",
    "        except:\n",
    "            raise ValueError(\"Estimator has to be fitted to get the correlation results\")\n",
    "        \n",
    "        # apply pandas dataframe operation on the fit output\n",
    "        corr_df = pd.DataFrame(self.matrix, columns=self.column_names, index=self.column_names)\n",
    "        final_corr_df = pd.DataFrame(corr_df.abs().unstack().sort_values(kind='quicksort')).reset_index()\n",
    "        final_corr_df.rename({'level_0': 'col1', 'level_1': 'col2', 0: 'correlation_value'}, axis=1, inplace=True)\n",
    "        final_corr_df = final_corr_df[final_corr_df['col1'] != final_corr_df['col2']]\n",
    "        \n",
    "        #shortlisted dataframe based on custom cutoff\n",
    "        shortlisted_corr_df = final_corr_df[final_corr_df['correlation_value'] > self.correlation_cutoff]\n",
    "        return corr_df, shortlisted_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customcorrelation import CustomCorrelation\n",
    "clf = CustomCorrelation(inputCol='features')\n",
    "output, shorlisted_output = clf.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorlisted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Compatability for custom Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude target variable and select all other feature vectors\n",
    "features_list = df.columns\n",
    "features_list.remove(target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from customcorrelation import CustomCorrelation\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = []\n",
    "\n",
    "#assemble vectors\n",
    "assembler = VectorAssembler(inputCols=features_list, outputCol='features')\n",
    "custom_corr = CustomCorrelation(inputCol=assembler.getOutputCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [assembler, custom_corr]\n",
    "\n",
    "#use pipeline to process sequentially\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline model\n",
    "pipelineModel = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply pipeline model on data\n",
    "output, shorlisted_output = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorlisted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
