{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative FIltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sparksession\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"CF\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.4 | packaged by conda-forge | (default, Jul 17 2020, 15:16:46) \n",
      "[GCC 7.5.0]\n",
      "Spark version: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "# Print PySpark and Python versions\n",
    "import sys\n",
    "print('Python version: '+sys.version)\n",
    "print('Spark version: '+spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_location = \"cf_data.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"true\"\n",
    "\n",
    "\n",
    "df = spark.read.format(file_type)\\\n",
    ".option(\"inferSchema\", infer_schema)\\\n",
    ".option(\"header\", first_row_is_header)\\\n",
    ".load(file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Metadata\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records in the credit card dataset are 98468\n"
     ]
    }
   ],
   "source": [
    "#  Count data\n",
    "df.count()\n",
    "print('The total number of records in the credit card dataset are '+str(df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import appropriate libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import appropriate libraries\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as sql_fun\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.475354940517705\n"
     ]
    }
   ],
   "source": [
    "# Casting variables\n",
    "int_vars=['userId','movieId']\n",
    "for column in int_vars:\n",
    "\tdf=df.withColumn(column,df[column].cast(IntegerType()))\n",
    "float_vars=['rating']\n",
    "for column in float_vars:\n",
    "\tdf=df.withColumn(column,df[column].cast(FloatType()))\n",
    "\n",
    "(training, test) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "als = ALS(rank=15,maxIter=2, regParam=0.01, \n",
    "          userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=False) \n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8947"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.count()\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "movieRecs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 2)\n",
      "(8947, 2)\n"
     ]
    }
   ],
   "source": [
    "userRecs_df = userRecs.toPandas()\n",
    "print(userRecs_df.shape)\n",
    "\n",
    "movieRecs_df = movieRecs.toPandas()\n",
    "print(movieRecs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190174</td>\n",
       "      <td>[(3436, 9.908001899719238), (54023, 9.61083316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190227</td>\n",
       "      <td>[(4771, 7.483070373535156), (8767, 7.309700012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190387</td>\n",
       "      <td>[(8767, 12.672131538391113), (1336, 12.2035512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190540</td>\n",
       "      <td>[(3277, 9.617005348205566), (33789, 9.22812843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190348</td>\n",
       "      <td>[(3436, 8.795571327209473), (3859, 8.479754447...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                    recommendations\n",
       "0  190174  [(3436, 9.908001899719238), (54023, 9.61083316...\n",
       "1  190227  [(4771, 7.483070373535156), (8767, 7.309700012...\n",
       "2  190387  [(8767, 12.672131538391113), (1336, 12.2035512...\n",
       "3  190540  [(3277, 9.617005348205566), (33789, 9.22812843...\n",
       "4  190348  [(3436, 8.795571327209473), (3859, 8.479754447..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
